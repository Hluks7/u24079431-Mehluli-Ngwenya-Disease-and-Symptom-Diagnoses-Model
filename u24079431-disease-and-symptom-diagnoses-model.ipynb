{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1182853,"sourceType":"datasetVersion","datasetId":672162},{"sourceId":7449146,"sourceType":"datasetVersion","datasetId":3316241},{"sourceId":7674502,"sourceType":"datasetVersion","datasetId":4476607},{"sourceId":9853241,"sourceType":"datasetVersion","datasetId":6046300}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mehlulingwenya/u24079431-disease-and-symptom-diagnoses-model?scriptVersionId=208606236\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-20T11:36:06.253276Z","iopub.execute_input":"2024-11-20T11:36:06.253743Z","iopub.status.idle":"2024-11-20T11:36:06.283079Z","shell.execute_reply.started":"2024-11-20T11:36:06.253701Z","shell.execute_reply":"2024-11-20T11:36:06.282229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split,KFold,cross_val_score,GridSearchCV\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix,classification_report,precision_score,roc_curve\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:06.284715Z","iopub.execute_input":"2024-11-20T11:36:06.285107Z","iopub.status.idle":"2024-11-20T11:36:07.912125Z","shell.execute_reply.started":"2024-11-20T11:36:06.285064Z","shell.execute_reply":"2024-11-20T11:36:07.910844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Read and shuffle the dataset**","metadata":{}},{"cell_type":"code","source":"#Read and output dataset\ndata = pd.read_csv('/kaggle/input/second-dataset-and-symptoms/symbipredict_2022.csv')\ndata = shuffle(data,random_state=42)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:07.913773Z","iopub.execute_input":"2024-11-20T11:36:07.914485Z","iopub.status.idle":"2024-11-20T11:36:08.091832Z","shell.execute_reply.started":"2024-11-20T11:36:07.914449Z","shell.execute_reply":"2024-11-20T11:36:08.090767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dataset Description\nprint(data.describe())","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.092918Z","iopub.execute_input":"2024-11-20T11:36:08.093237Z","iopub.status.idle":"2024-11-20T11:36:08.321813Z","shell.execute_reply.started":"2024-11-20T11:36:08.093189Z","shell.execute_reply":"2024-11-20T11:36:08.320725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Total null values found\nprint(data.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.323932Z","iopub.execute_input":"2024-11-20T11:36:08.324287Z","iopub.status.idle":"2024-11-20T11:36:08.33319Z","shell.execute_reply.started":"2024-11-20T11:36:08.324255Z","shell.execute_reply":"2024-11-20T11:36:08.332042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.columns)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.334407Z","iopub.execute_input":"2024-11-20T11:36:08.334707Z","iopub.status.idle":"2024-11-20T11:36:08.343749Z","shell.execute_reply.started":"2024-11-20T11:36:08.334679Z","shell.execute_reply":"2024-11-20T11:36:08.342382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns = data.columns.str.strip('_')","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.345535Z","iopub.execute_input":"2024-11-20T11:36:08.345973Z","iopub.status.idle":"2024-11-20T11:36:08.357795Z","shell.execute_reply.started":"2024-11-20T11:36:08.345928Z","shell.execute_reply":"2024-11-20T11:36:08.356819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.columns)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.358955Z","iopub.execute_input":"2024-11-20T11:36:08.359284Z","iopub.status.idle":"2024-11-20T11:36:08.370604Z","shell.execute_reply.started":"2024-11-20T11:36:08.359255Z","shell.execute_reply":"2024-11-20T11:36:08.369601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the distribution of the target variable (Disease)\nprint(data['prognosis'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.371885Z","iopub.execute_input":"2024-11-20T11:36:08.372242Z","iopub.status.idle":"2024-11-20T11:36:08.389473Z","shell.execute_reply.started":"2024-11-20T11:36:08.372194Z","shell.execute_reply":"2024-11-20T11:36:08.388198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read And Print Symptom Dataset\n\ndata2 = pd.read_csv('/kaggle/input/disease-symptom-description-dataset/Symptom-severity.csv')\ndata2['Symptom'] = data2['Symptom'].str.replace('_',' ')\ndata2.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.390951Z","iopub.execute_input":"2024-11-20T11:36:08.391383Z","iopub.status.idle":"2024-11-20T11:36:08.423684Z","shell.execute_reply.started":"2024-11-20T11:36:08.391337Z","shell.execute_reply":"2024-11-20T11:36:08.422668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2['Symptom'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.427464Z","iopub.execute_input":"2024-11-20T11:36:08.427805Z","iopub.status.idle":"2024-11-20T11:36:08.438195Z","shell.execute_reply.started":"2024-11-20T11:36:08.427767Z","shell.execute_reply":"2024-11-20T11:36:08.437012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = data.columns\n# Flatten the DataFrame to a 1D array\ndata_flat = data.values.flatten()\n\n# Create a Series and strip whitespace (only apply to string elements)\ns = pd.Series(data_flat)\ns = s.apply(lambda x: x.strip() if isinstance(x, str) else x)\n\n# Check if the original and cleaned arrays match in length\nif s.size == data.size:\n    # Reshape the cleaned data back to the original shape\n    s_reshaped = s.values.reshape(data.shape)\n    \n    # Create a new DataFrame with the original column names\n    data_cleaned = pd.DataFrame(s_reshaped, columns=cols)\n    \n    # Display the cleaned DataFrame\n    data_cleaned.head()\nelse:\n    print(\"Mismatch in the number of elements between original and cleaned data.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.439672Z","iopub.execute_input":"2024-11-20T11:36:08.440107Z","iopub.status.idle":"2024-11-20T11:36:08.600605Z","shell.execute_reply.started":"2024-11-20T11:36:08.440062Z","shell.execute_reply":"2024-11-20T11:36:08.599388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Handling Missing Values**","metadata":{}},{"cell_type":"code","source":"# Handle any missing values if present (example: fill with mode)\ndata = data.fillna(0)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.601785Z","iopub.execute_input":"2024-11-20T11:36:08.602067Z","iopub.status.idle":"2024-11-20T11:36:08.623185Z","shell.execute_reply.started":"2024-11-20T11:36:08.60204Z","shell.execute_reply":"2024-11-20T11:36:08.621983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize the symptoms and values for matching\nvals = np.char.lower(np.char.strip(data.values.astype(str)))  # Convert to lowercase and strip spaces\nsymptoms = [sym.lower().strip() for sym in data2['Symptom'].unique()]\n\n# Replace the values in the array with the corresponding weights\nfor i in range(len(symptoms)):\n    mask = vals == symptoms[i]  # Find matches for the current symptom\n    if mask.any():  # Check if there are any matches\n        vals[mask] = data2.loc[data2['Symptom'].str.lower().str.strip() == symptoms[i], 'weight'].values[0]\n\n# Create the cleaned DataFrame\nd = pd.DataFrame(vals, columns=cols)\nd.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:08.624344Z","iopub.execute_input":"2024-11-20T11:36:08.624645Z","iopub.status.idle":"2024-11-20T11:36:10.513235Z","shell.execute_reply.started":"2024-11-20T11:36:08.624616Z","shell.execute_reply":"2024-11-20T11:36:10.512256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = d.replace('dischromic  patches', 0)\nd = d.replace('spotting  urination',0)\ndata = d.replace('foul smell of urine',0)\ndata.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:10.514662Z","iopub.execute_input":"2024-11-20T11:36:10.514993Z","iopub.status.idle":"2024-11-20T11:36:10.713683Z","shell.execute_reply.started":"2024-11-20T11:36:10.514963Z","shell.execute_reply":"2024-11-20T11:36:10.712602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_checker = data.apply(lambda x: sum(x.isnull())).to_frame(name='count')\nprint(null_checker)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:10.715Z","iopub.execute_input":"2024-11-20T11:36:10.715345Z","iopub.status.idle":"2024-11-20T11:36:10.820735Z","shell.execute_reply.started":"2024-11-20T11:36:10.715313Z","shell.execute_reply":"2024-11-20T11:36:10.819551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.plot(null_checker.index, null_checker['count'])\nplt.xticks(null_checker.index, null_checker.index, rotation=45,\nhorizontalalignment='right')\nplt.title('After removing Null values')\nplt.xlabel('column names')\nplt.margins(0.01)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:10.822153Z","iopub.execute_input":"2024-11-20T11:36:10.822596Z","iopub.status.idle":"2024-11-20T11:36:11.946722Z","shell.execute_reply.started":"2024-11-20T11:36:10.82254Z","shell.execute_reply":"2024-11-20T11:36:11.945557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Training**","metadata":{}},{"cell_type":"code","source":"print(\"Number of symptoms used to identify the disease \",len(data2['Symptom'].unique()))\nprint(\"Number of diseases that can be identified \",len(data['prognosis'].unique()))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:11.948053Z","iopub.execute_input":"2024-11-20T11:36:11.94838Z","iopub.status.idle":"2024-11-20T11:36:11.956066Z","shell.execute_reply.started":"2024-11-20T11:36:11.94835Z","shell.execute_reply":"2024-11-20T11:36:11.954602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['prognosis'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:11.957341Z","iopub.execute_input":"2024-11-20T11:36:11.957656Z","iopub.status.idle":"2024-11-20T11:36:11.978593Z","shell.execute_reply.started":"2024-11-20T11:36:11.957625Z","shell.execute_reply":"2024-11-20T11:36:11.977581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the 'Disease' column as labels before converting to NumPy array\nlabels = data['prognosis'].values\n\n# Convert the features to a NumPy array, excluding the 'Disease' column\nfeatures = data.iloc[:, 1:].values\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:11.979771Z","iopub.execute_input":"2024-11-20T11:36:11.980106Z","iopub.status.idle":"2024-11-20T11:36:11.992337Z","shell.execute_reply.started":"2024-11-20T11:36:11.980074Z","shell.execute_reply":"2024-11-20T11:36:11.99132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(data, labels, train_size = 0.8,random_state=42)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:11.993662Z","iopub.execute_input":"2024-11-20T11:36:11.993978Z","iopub.status.idle":"2024-11-20T11:36:12.017583Z","shell.execute_reply.started":"2024-11-20T11:36:11.993949Z","shell.execute_reply":"2024-11-20T11:36:12.016336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n# Step 1: Ensure consistent data types for training and testing\n# If not done previously, convert categorical columns to strings\ncategorical_columns = x_train.select_dtypes(include=['object']).columns\nfor col in categorical_columns:\n    x_train[col] = x_train[col].astype(str)\n    x_test[col] = x_test[col].astype(str)\n\n# Step 2: Apply Label Encoding to convert categorical data into numerical form\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoders = {}\nfor col in categorical_columns:\n    le = LabelEncoder()\n    x_train[col] = le.fit_transform(x_train[col])\n    x_test[col] = le.transform(x_test[col])\n    label_encoders[col] = le  # Store encoders for potential future use\n\n# Step 3: Ensure all columns are numerical (optional but recommended)\nx_train = x_train.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\nx_test = x_test.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n\n# Step 4: Initialize and train the Logistic Regression model\nlog_reg = LogisticRegression(max_iter=2000, random_state=42)\nlog_reg.fit(x_train, y_train)\n\n# Step 5: Make predictions\npreds = log_reg.predict(x_test)\n\n# Step 6: Print predictions for the first instance for inspection\nprint(x_test.iloc[0])\nprint(preds[0])\n\n# Step 7: Evaluate the model\nconf_mat = confusion_matrix(y_test, preds)\nunique_labels = np.unique(y_test)\ndf_cm = pd.DataFrame(conf_mat, index=unique_labels, columns=unique_labels)\n\n# Print F1-score, accuracy, and classification report\nprint('F1-score% =', f1_score(y_test, preds, average='macro') * 100)\nprint('Accuracy% =', accuracy_score(y_test, preds) * 100)\nprint(classification_report(y_test, preds))\n\n# Plot the confusion matrix\nsns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:12.019252Z","iopub.execute_input":"2024-11-20T11:36:12.020241Z","iopub.status.idle":"2024-11-20T11:36:41.77477Z","shell.execute_reply.started":"2024-11-20T11:36:12.020161Z","shell.execute_reply":"2024-11-20T11:36:41.773706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Convert y_train and y_test to Pandas Series\ny_train_series = pd.Series(y_train)\ny_test_series = pd.Series(y_test)\n\n# Plot class distributions\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n# Training set distribution\ny_train_series.value_counts().plot(kind='bar', ax=axes[0])\naxes[0].set_title('Training Set Class Distribution')\naxes[0].set_xlabel('Disease')\naxes[0].set_ylabel('Count')\n\n# Test set distribution\ny_test_series.value_counts().plot(kind='bar', ax=axes[1])\naxes[1].set_title('Test Set Class Distribution')\naxes[1].set_xlabel('Disease')\naxes[1].set_ylabel('Count')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:41.776235Z","iopub.execute_input":"2024-11-20T11:36:41.776635Z","iopub.status.idle":"2024-11-20T11:36:42.760637Z","shell.execute_reply.started":"2024-11-20T11:36:41.776592Z","shell.execute_reply":"2024-11-20T11:36:42.759615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\n# Define the parameter grid\nparam_grid = {\n    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n    'solver': ['liblinear', 'lbfgs'],  # Optimization algorithms\n    'max_iter': [500, 700, 1000]  # Maximum iterations\n}\n\n# Initialize the model\nlog_reg = LogisticRegression(random_state=42)\n\n# Set up GridSearchCV\ngrid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n\n# Fit to the training data\ngrid_search.fit(x_train, y_train)\n\n# Best parameters and score\nprint(\"Best Parameters:\", grid_search.best_params_)\nprint(\"Best Cross-Validation Accuracy: %.2f%%\" % (grid_search.best_score_ * 100))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:36:42.762119Z","iopub.execute_input":"2024-11-20T11:36:42.762568Z","iopub.status.idle":"2024-11-20T11:43:29.737879Z","shell.execute_reply.started":"2024-11-20T11:36:42.762524Z","shell.execute_reply":"2024-11-20T11:43:29.736602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\n# Initialize the Logistic Regression model\nlog_reg = LogisticRegression(max_iter=2000, random_state=42)\n\n# Define the K-Fold cross-validator\nkfold = KFold(n_splits=10, shuffle=True, random_state=42)\n\n# Perform cross-validation using Logistic Regression\nDS_train = cross_val_score(log_reg, x_train, y_train, cv=kfold, scoring='accuracy')\n\n# Create a DataFrame with the scores\nscores_df = pd.DataFrame(DS_train, columns=['Scores'])\nprint(scores_df)\n\n# Print the mean accuracy and standard deviation\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (DS_train.mean() * 100.0, DS_train.std() * 100.0))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:43:29.739754Z","iopub.execute_input":"2024-11-20T11:43:29.740155Z","iopub.status.idle":"2024-11-20T11:47:25.593971Z","shell.execute_reply.started":"2024-11-20T11:43:29.740114Z","shell.execute_reply":"2024-11-20T11:47:25.592251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Random Forest Tree Model**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, f1_score, accuracy_score\nimport seaborn as sns\nimport pandas as pd\n\n# Initialize and train the Random Forest model\nrnd_forest = RandomForestClassifier(random_state=42, max_features='sqrt', n_estimators=500, max_depth=13)\nrnd_forest.fit(x_train, y_train)\n\n# Make predictions\npreds = rnd_forest.predict(x_test)\n\n# Print the first row of x_test and the first prediction for inspection\nprint(x_test.iloc[0])  # Access the first row using iloc\nprint(preds[0])\n\n# Generate the confusion matrix\nconf_mat = confusion_matrix(y_test, preds)\n\n# Get unique labels using np.unique since y_test is a NumPy array\nunique_labels = np.unique(y_test)\ndf_cm = pd.DataFrame(conf_mat, index=unique_labels, columns=unique_labels)\n\n# Print F1-score and accuracy\nprint('F1-score% =', f1_score(y_test, preds, average='macro') * 100, '| Accuracy% =', accuracy_score(y_test, preds) * 100)\n\n# Plot the confusion matrix\nsns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:47:25.595217Z","iopub.execute_input":"2024-11-20T11:47:25.595609Z","iopub.status.idle":"2024-11-20T11:47:31.43459Z","shell.execute_reply.started":"2024-11-20T11:47:25.595565Z","shell.execute_reply":"2024-11-20T11:47:31.433408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Define the parameter grid\nparam_grid = {\n    'n_estimators': [100, 300, 500],\n    'max_depth': [10, 20, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Initialize the model\nrnd_forest = RandomForestClassifier(random_state=42)\n\n# Set up GridSearchCV\ngrid_search = GridSearchCV(estimator=rnd_forest, param_grid=param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n\n# Fit to the training data\ngrid_search.fit(x_train, y_train)\n\n# Best parameters and score\nprint(\"Best Parameters:\", grid_search.best_params_)\nprint(\"Best Cross-Validation Accuracy: %.2f%%\" % (grid_search.best_score_ * 100))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:47:31.435751Z","iopub.execute_input":"2024-11-20T11:47:31.436036Z","iopub.status.idle":"2024-11-20T11:54:08.09865Z","shell.execute_reply.started":"2024-11-20T11:47:31.436008Z","shell.execute_reply":"2024-11-20T11:54:08.09757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nrnd_forest_train =cross_val_score(rnd_forest, x_train, y_train, cv=kfold, scoring='accuracy')\npd.DataFrame(rnd_forest_train,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (rnd_forest_train.mean()*100.0, rnd_forest_train.std()*100.0))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:54:08.099973Z","iopub.execute_input":"2024-11-20T11:54:08.10032Z","iopub.status.idle":"2024-11-20T11:54:12.53202Z","shell.execute_reply.started":"2024-11-20T11:54:08.100285Z","shell.execute_reply":"2024-11-20T11:54:12.530841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nrnd_forest_train =cross_val_score(rnd_forest, x_train, y_train, cv=kfold, scoring='accuracy')\npd.DataFrame(rnd_forest_train,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (rnd_forest_train.mean()*100.0, rnd_forest_train.std()*100.0))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:54:12.536391Z","iopub.execute_input":"2024-11-20T11:54:12.536736Z","iopub.status.idle":"2024-11-20T11:54:16.896102Z","shell.execute_reply.started":"2024-11-20T11:54:12.536703Z","shell.execute_reply":"2024-11-20T11:54:16.894976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, KFold\nimport pandas as pd\n\n# Step 1: Scale the data\nscaler = StandardScaler()\nx_train_scaled = scaler.fit_transform(x_train)  # Ensure x_train is defined\nx_test_scaled = scaler.transform(x_test)        # Ensure x_test is defined\n\n# Step 2: Initialize models\nlog_reg = LogisticRegression(max_iter=1000, random_state=42)\nrnd_forest = RandomForestClassifier(random_state=42, max_features='sqrt', n_estimators=500, max_depth=13)\n\n# Step 3: KFold cross-validation\nkfold = KFold(n_splits=10, shuffle=True, random_state=42)\n\n# Step 4: Cross-validation scores\nlog_reg_scores = cross_val_score(log_reg, x_train_scaled, y_train, cv=kfold, scoring='accuracy')\nrnd_forest_scores = cross_val_score(rnd_forest, x_train_scaled, y_train, cv=kfold, scoring='accuracy')\n\n# Step 5: Print mean accuracy and standard deviation\nprint(\"Logistic Regression - Mean Accuracy: %.3f%%, Std Dev: (%.2f%%)\" % (log_reg_scores.mean() * 100, log_reg_scores.std() * 100))\nprint(\"Random Forest - Mean Accuracy: %.3f%%, Std Dev: (%.2f%%)\" % (rnd_forest_scores.mean() * 100, rnd_forest_scores.std() * 100))\n\n# Step 6: Create a DataFrame for comparison\ncomparison_df = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Random Forest'],\n    'Mean Accuracy': [log_reg_scores.mean() * 100, rnd_forest_scores.mean() * 100],\n    'Std Dev': [log_reg_scores.std() * 100, rnd_forest_scores.std() * 100]\n})\nprint(comparison_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:54:16.897578Z","iopub.execute_input":"2024-11-20T11:54:16.897988Z","iopub.status.idle":"2024-11-20T11:54:46.853487Z","shell.execute_reply.started":"2024-11-20T11:54:16.897941Z","shell.execute_reply":"2024-11-20T11:54:46.852363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Create a DataFrame for comparison (if not already created)\ncomparison_df = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Random Forest'],\n    'Mean Accuracy': [log_reg_scores.mean() * 100, rnd_forest_scores.mean() * 100],\n    'Std Dev': [log_reg_scores.std() * 100, rnd_forest_scores.std() * 100]\n})\n\n# Plot a bar chart for Mean Accuracy with error bars for Std Dev\nplt.figure(figsize=(10, 6))\nplt.bar(comparison_df['Model'], comparison_df['Mean Accuracy'], yerr=comparison_df['Std Dev'], \n        capsize=5, color=['skyblue', 'lightgreen'])\nplt.title('Comparison of Model Performance')\nplt.ylabel('Mean Accuracy (%)')\nplt.xlabel('Model')\nplt.ylim([0, 100])  # Set y-axis limit for better visualization\n\n# Display the chart\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:54:46.854772Z","iopub.execute_input":"2024-11-20T11:54:46.855091Z","iopub.status.idle":"2024-11-20T11:54:47.093219Z","shell.execute_reply.started":"2024-11-20T11:54:46.85506Z","shell.execute_reply":"2024-11-20T11:54:47.091889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Saved Model (Logistic Regression Model)**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom joblib import dump, load  # Ensuring this import is at the top of script\n\n# Train a Random Forest model\nrnd_forest = RandomForestClassifier(random_state=42, max_features='sqrt', n_estimators=500, max_depth=13)\nrnd_forest.fit(x_train, y_train)\ndump(rnd_forest, 'random_forest_model.joblib')\n\n# Train a Logistic Regression model\nlog_reg = LogisticRegression(max_iter=2000, random_state=42)\nlog_reg.fit(x_train_scaled, y_train)\ndump(log_reg, '/kaggle/working/logistic_regression_model.joblib')","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:54:47.094806Z","iopub.execute_input":"2024-11-20T11:54:47.095198Z","iopub.status.idle":"2024-11-20T11:54:50.544636Z","shell.execute_reply.started":"2024-11-20T11:54:47.095134Z","shell.execute_reply":"2024-11-20T11:54:50.54327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the training columns correctly\ntraining_columns_df = pd.read_csv('/kaggle/input/second-dataset-and-symptoms/symbipredict_2022.csv', header=None)\n\n# Ensuring that only the first column is used \ntraining_columns = training_columns_df.iloc[:, 0].tolist()  # Access the first column and convert to a list\n\n# Print to verify that the training columns are loaded correctly\nprint(training_columns)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:54:50.546188Z","iopub.execute_input":"2024-11-20T11:54:50.546717Z","iopub.status.idle":"2024-11-20T11:54:50.68591Z","shell.execute_reply.started":"2024-11-20T11:54:50.546656Z","shell.execute_reply":"2024-11-20T11:54:50.684822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**First Prediction Without Prompt from User At Random**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom joblib import load  # For loading a saved model\n\n# Load your trained model \nmodel = load('/kaggle/working/logistic_regression_model.joblib')  # Replace with your model filename\n\n# Load or define the encoders used during training for consistent encoding\nlabel_encoders = {} \n\n# Sample symptoms list to match training format\nsymptoms_list = data2['Symptom']  # Replace with actual columns/symptoms used during training\n\n# Extract feature columns from the original training DataFrame used for training\ntraining_columns = x_train.columns.tolist()  # Ensure `x_train` is the DataFrame used during model training\n\n# Function to ensure user input matches the training features\ndef encode_user_input(input_symptoms, training_columns, label_encoders):\n    user_data = {col: 0 for col in training_columns}  # Initialize with zeros for all features\n    for symptom in input_symptoms:\n        if symptom in user_data:\n            user_data[symptom] = 1\n    user_df = pd.DataFrame([user_data])\n    \n    # Apply LabelEncoder if needed\n    for col in user_df.columns:\n        if col in label_encoders:\n            user_df[col] = label_encoders[col].transform(user_df[col])\n    return user_df\n\ndef predict_disease(input_symptoms):\n    # Encode the user input\n    user_input_encoded = encode_user_input(input_symptoms, training_columns, label_encoders)\n\n    # Ensuring columns match the training data\n    user_input_encoded = user_input_encoded[training_columns]  # Reorder and align columns\n\n    # Convert DataFrame to NumPy array to avoid feature name warnings\n    user_input_array = user_input_encoded.values\n\n    # Predict disease\n    prediction = model.predict(user_input_array)\n    return prediction[0]\n\n# Example usage:\nuser_symptoms = data2['Symptom']  # Replace with actual user input\npredicted_disease = predict_disease(user_symptoms)\nprint(f\"Predicted Disease: {predicted_disease}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:54:50.687284Z","iopub.execute_input":"2024-11-20T11:54:50.687621Z","iopub.status.idle":"2024-11-20T11:54:50.70496Z","shell.execute_reply.started":"2024-11-20T11:54:50.68759Z","shell.execute_reply":"2024-11-20T11:54:50.703706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrain the model with feature names\nlog_reg = LogisticRegression(max_iter=2000, random_state=42)\nlog_reg.fit(x_train, y_train)  # Ensure x_train is a DataFrame\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:54:50.706538Z","iopub.execute_input":"2024-11-20T11:54:50.706988Z","iopub.status.idle":"2024-11-20T11:55:15.986378Z","shell.execute_reply.started":"2024-11-20T11:54:50.706939Z","shell.execute_reply":"2024-11-20T11:55:15.983961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**User-Prompt**","metadata":{}},{"cell_type":"code","source":"# List of known symptoms from the training data\nknown_symptoms = set(training_columns)  # Ensure this matches your model's features\n\ndef validate_input(input_symptoms):\n    invalid_symptoms = [symptom for symptom in input_symptoms if symptom not in known_symptoms]\n    if invalid_symptoms:\n        print(f\"Warning: These symptoms are not recognized: {', '.join(invalid_symptoms)}\")\n        return False\n    return True\n\n# Modify the user input function\ndef get_user_input_and_predict():\n    input_text = input(\"Please enter your symptoms, separated by commas: \")\n    user_symptoms = [symptom.strip() for symptom in input_text.split(',')]\n    \n    if not validate_input(user_symptoms):\n        print(\"Please enter valid symptoms.\")\n        return\n    \n    predicted_disease = predict_disease(user_symptoms)\n    print(f\"Predicted Disease: {predicted_disease}\")\n\nget_user_input_and_predict()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T11:55:15.989142Z","iopub.execute_input":"2024-11-20T11:55:15.99167Z","iopub.status.idle":"2024-11-20T11:55:37.992266Z","shell.execute_reply.started":"2024-11-20T11:55:15.991591Z","shell.execute_reply":"2024-11-20T11:55:37.99118Z"},"trusted":true},"execution_count":null,"outputs":[]}]}